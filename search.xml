<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>接入世界第一步</title>
      <link href="/2025/02/19/hello-world/"/>
      <url>/2025/02/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 某些记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类</title>
      <link href="/2025/02/19/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%20copy/"/>
      <url>/2025/02/19/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%20copy/</url>
      
        <content type="html"><![CDATA[<h1 id="video1-卷积神经网络"><a href="#video1-卷积神经网络" class="headerlink" title="video1:卷积神经网络"></a>video1:卷积神经网络</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/jpeg/32561980/1738909907542-8ece0c5c-5000-4e91-8e8f-4957b64f1484.jpeg" alt="画板"></p><h1 id="video2-补充：误差-反向传播"><a href="#video2-补充：误差-反向传播" class="headerlink" title="video2:补充：误差 反向传播"></a>video2:补充：误差 反向传播</h1><h2 id="1-计算误差值"><a href="#1-计算误差值" class="headerlink" title="1.计算误差值"></a>1.计算误差值</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738910345072-f377ec5f-c9dd-4766-9c5f-c8b067242a1d.png"></p><h2 id="2-计算损失值loss"><a href="#2-计算损失值loss" class="headerlink" title="2.计算损失值loss"></a>2.计算损失值loss</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738910478675-36d18996-48ac-4aa0-82a8-b1452bad4c24.png"></p><h2 id="3-计算损失梯度，更新权重值"><a href="#3-计算损失梯度，更新权重值" class="headerlink" title="3.计算损失梯度，更新权重值"></a>3.计算损失梯度，更新权重值</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911129508-d99bc876-ab92-404e-b8ce-f8afa4c31cea.png"></p><h2 id="优化器optimizer：分批次训练，为了使网络更快的收敛"><a href="#优化器optimizer：分批次训练，为了使网络更快的收敛" class="headerlink" title="优化器optimizer：分批次训练，为了使网络更快的收敛"></a>优化器optimizer：分批次训练，为了使网络更快的收敛</h2><h3 id="1-SGD优化器"><a href="#1-SGD优化器" class="headerlink" title="1.SGD优化器"></a>1.SGD优化器</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911704229-9de6047d-06b0-4613-8c9b-758e3590a03e.png"></p><h3 id="2-SGD-Moementum优化器"><a href="#2-SGD-Moementum优化器" class="headerlink" title="2.SGD+Moementum优化器"></a>2.SGD+Moementum优化器</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911795030-bc996492-74f0-4529-b503-5e8787c81cb1.png"></p><h3 id="3-Adagrad优化器（自适应学习率）"><a href="#3-Adagrad优化器（自适应学习率）" class="headerlink" title="3.Adagrad优化器（自适应学习率）"></a>3.Adagrad优化器（自适应学习率）</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911909581-6511d462-5f87-40c6-ab92-3732fb650c0f.png"></p><h3 id="4-RMSProp优化器（自适应学习率）"><a href="#4-RMSProp优化器（自适应学习率）" class="headerlink" title="4.RMSProp优化器（自适应学习率）"></a>4.RMSProp优化器（自适应学习率）</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911967584-b0fcf198-69a6-4f40-8a8d-c67432b77f25.png"></p><h3 id="5-Adam优化器（自适应学习率）"><a href="#5-Adam优化器（自适应学习率）" class="headerlink" title="5.Adam优化器（自适应学习率）"></a>5.Adam优化器（自适应学习率）</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738912033673-8dc8f94d-b795-4469-94fa-4f2be0ac69df.png"></p><h3 id="6-总览"><a href="#6-总览" class="headerlink" title="6.总览"></a>6.总览</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738912100915-36e4e81d-72c9-49c1-b017-736083ad1b5a.png"></p><h1 id="video3-pytorch-demo"><a href="#video3-pytorch-demo" class="headerlink" title="video3:pytorch demo"></a>video3:pytorch demo</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738912519122-0b6ca640-97e3-449e-ac34-684da13be146.png"></p><h2 id="test1-official-demo"><a href="#test1-official-demo" class="headerlink" title="test1_official_demo"></a>test1_official_demo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)<span class="comment">#卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)<span class="comment">#卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行图像格式转换</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50000张训练图片的数据集下载</span></span><br><span class="line"><span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                         download=<span class="literal">False</span>, transform=transform)</span><br><span class="line"><span class="comment">#创建训练数据加载器，设置批量大小、是否打乱数据和工作线程数</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">36</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 10000张验证图片</span></span><br><span class="line">val_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">False</span>, transform=transform)</span><br><span class="line"><span class="comment">#创建验证数据加载器，设置批量大小、是否打乱数据和工作线程数</span></span><br><span class="line">val_loader = torch.utils.data.DataLoader(val_set, batch_size=<span class="number">10000</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 创建一个迭代器 val_data_iter，用于遍历 val_loader。</span></span><br><span class="line"><span class="comment"># 使用 next 函数从迭代器中获取一批验证数据，包括图像 val_image 和标签 val_label</span></span><br><span class="line">val_data_iter = <span class="built_in">iter</span>(val_loader)</span><br><span class="line">val_image, val_label = <span class="built_in">next</span>(val_data_iter)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"><span class="comment"># 初始化LeNet模型</span></span><br><span class="line">net = LeNet()</span><br><span class="line"><span class="comment"># 定义损失函数为交叉熵损失</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 使用Adam优化器，学习率为0.001</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = loss_function(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:    <span class="comment"># print every 500 mini-batches</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                outputs = net(val_image)  <span class="comment"># [batch, 10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = torch.eq(predict_y, val_label).<span class="built_in">sum</span>().item() / val_label.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;/n [%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line"><span class="comment">#使用 torch.save 函数保存神经网络 net 的状态字典（即模型参数）到指定路径。</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/__mermaid_v3/7cbe5a2ec49a252efc8df44dd63282c7.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用 transform 函数对图像进行转换，输出格式为 [通道数, 高度, 宽度]。</span></span><br><span class="line">im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line"><span class="comment"># 使用 torch.unsqueeze 增加一个维度，使图像张量的形状变为 [批次大小, 通道数, 高度, 宽度]。</span></span><br><span class="line">im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># [N, C, H, W]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.no_grad() 禁用梯度计算，提高推理速度</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    <span class="comment"># 对输出进行处理，取最大值对应的类别索引，并转换为 numpy 数组。</span></span><br><span class="line">    predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测结果：&#x27;</span>+classes[<span class="built_in">int</span>(predict)])</span><br></pre></td></tr></table></figure><h1 id="video4-tensorflow-demo"><a href="#video4-tensorflow-demo" class="headerlink" title="video4:tensorflow demo"></a>video4:tensorflow demo</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1739001055794-fdf74acb-c28e-461e-906c-bedc939f53f0.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1739001466021-1db3c6f9-8906-403e-a0ce-f3e50924e5d2.png" alt="卷积过程不需要padding参数的时候设置为valid （filter卷积核）"></p><h2 id="test1-official-demo-1"><a href="#test1-official-demo-1" class="headerlink" title="test1_official_demo"></a>test1_official_demo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten, Conv2D</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 卷积层，第一个参数为卷积核的个数，第二个参数为卷积核的大小，第三个参数为激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        <span class="comment"># 展平操作</span></span><br><span class="line">        <span class="variable language_">self</span>.flatten = Flatten()</span><br><span class="line">        <span class="comment"># 全连接层，第一个参数为输出的维度，第二个参数为激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.d2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">        <span class="comment">#softmax返回的概率分布值，即预测值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正向传播过程</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)      <span class="comment"># input[batch, 28, 28, 1] output[batch, 26, 26, 32]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)    <span class="comment"># output [batch, 21632]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.d1(x)         <span class="comment"># output [batch, 128]</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.d2(x)      <span class="comment"># output [batch, 10]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, division, print_function, unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> MyModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手写数字的一个数据集</span></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># download and load data</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># imgs = x_test[:3]</span></span><br><span class="line"><span class="comment"># labs = y_test[:3]</span></span><br><span class="line"><span class="comment"># print(labs)</span></span><br><span class="line"><span class="comment"># #对图片进行水平方向上的拼接</span></span><br><span class="line"><span class="comment"># plot_imags = np.hstack(imgs)</span></span><br><span class="line"><span class="comment"># plt.imshow(plot_imags, cmap=&#x27;gray&#x27;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a channels dimension</span></span><br><span class="line">x_train = x_train[..., tf.newaxis]</span><br><span class="line">x_test = x_test[..., tf.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># create data generator</span></span><br><span class="line"><span class="comment"># 使用 tf.data.Dataset.from_tensor_slices 将训练和测试数据转换为 TensorFlow 数据集。</span></span><br><span class="line"><span class="comment"># 对训练数据进行打乱（shuffle）操作，缓冲区大小为10000。</span></span><br><span class="line"><span class="comment"># 将训练和测试数据集按批次（batch）处理，每批次包含32个样本。</span></span><br><span class="line">train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line">test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define loss</span></span><br><span class="line"><span class="comment"># 创建一个稀疏分类交叉熵损失函数对象。该损失函数用于计算真实标签与预测概率之间的差异，适用于多分类问题，其中真实标签为整数形式的类别索引。</span></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define optimizer</span></span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train_loss and train_accuracy</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">&#x27;train_loss&#x27;</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;train_accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train_loss and train_accuracy</span></span><br><span class="line">test_loss = tf.keras.metrics.Mean(name=<span class="string">&#x27;test_loss&#x27;</span>)</span><br><span class="line">test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;test_accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train function including calculating loss, applying gradient and calculating accuracy</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">images, labels</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 用于跟踪梯度</span></span><br><span class="line">        <span class="comment"># 正向传播</span></span><br><span class="line">        predictions = model(images)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = loss_object(labels, predictions)</span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    <span class="comment"># 应用梯度来进行优化</span></span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, model.trainable_variables))</span><br><span class="line">    <span class="comment"># 更新训练损失和准确率</span></span><br><span class="line">    train_loss(loss)</span><br><span class="line">    train_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define test function including calculating loss and calculating accuracy</span></span><br><span class="line"><span class="comment"># 装饰器作用：将python代码转为tensorflow的计算图（图模型结构，理解为静态图），不能在再进行调试但可以提高运行效率</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">images, labels</span>):</span><br><span class="line">    <span class="comment"># 测试过程中不需要更新梯度，不用with tf.GradientTape()</span></span><br><span class="line">    <span class="comment"># 正向传播</span></span><br><span class="line">    predictions = model(images)</span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    t_loss = loss_object(labels, predictions)</span><br><span class="line">    <span class="comment"># 更新测试损失和准确率</span></span><br><span class="line">    test_loss(t_loss)</span><br><span class="line">    test_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    train_loss.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line">    train_accuracy.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line">    test_loss.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line">    test_accuracy.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(images, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> test_images, test_labels <span class="keyword">in</span> test_ds:</span><br><span class="line">        test_step(test_images, test_labels)</span><br><span class="line"></span><br><span class="line">    template = <span class="string">&#x27;Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;%, Test Loss: &#123;&#125;, Test Accuracy: &#123;&#125;%&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(template.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                          train_loss.result(),</span><br><span class="line">                          train_accuracy.result() * <span class="number">100</span>,</span><br><span class="line">                          test_loss.result(),</span><br><span class="line">                          test_accuracy.result() * <span class="number">100</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="video5：AlexNet"><a href="#video5：AlexNet" class="headerlink" title="video5：AlexNet"></a>video5：AlexNet</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1739867109895-6a18ad3f-b848-42cc-8c55-2a3f218340ea.png"></p><h1 id="video6-AlexNet与花分类（pytorch）"><a href="#video6-AlexNet与花分类（pytorch）" class="headerlink" title="video6:AlexNet与花分类（pytorch）"></a>video6:AlexNet与花分类（pytorch）</h1><h1 id="video7-AlexNet与花分类（TensorFlow）"><a href="#video7-AlexNet与花分类（TensorFlow）" class="headerlink" title="video7:AlexNet与花分类（TensorFlow）"></a>video7:AlexNet与花分类（TensorFlow）</h1>]]></content>
      
      
      <categories>
          
          <category> 编程学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类</title>
      <link href="/2025/02/19/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
      <url>/2025/02/19/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="video1-卷积神经网络"><a href="#video1-卷积神经网络" class="headerlink" title="video1:卷积神经网络"></a>video1:卷积神经网络</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/jpeg/32561980/1738909907542-8ece0c5c-5000-4e91-8e8f-4957b64f1484.jpeg" alt="画板"></p><h1 id="video2-补充：误差-反向传播"><a href="#video2-补充：误差-反向传播" class="headerlink" title="video2:补充：误差 反向传播"></a>video2:补充：误差 反向传播</h1><h2 id="1-计算误差值"><a href="#1-计算误差值" class="headerlink" title="1.计算误差值"></a>1.计算误差值</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738910345072-f377ec5f-c9dd-4766-9c5f-c8b067242a1d.png"></p><h2 id="2-计算损失值loss"><a href="#2-计算损失值loss" class="headerlink" title="2.计算损失值loss"></a>2.计算损失值loss</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738910478675-36d18996-48ac-4aa0-82a8-b1452bad4c24.png"></p><h2 id="3-计算损失梯度，更新权重值"><a href="#3-计算损失梯度，更新权重值" class="headerlink" title="3.计算损失梯度，更新权重值"></a>3.计算损失梯度，更新权重值</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911129508-d99bc876-ab92-404e-b8ce-f8afa4c31cea.png"></p><h2 id="优化器optimizer：分批次训练，为了使网络更快的收敛"><a href="#优化器optimizer：分批次训练，为了使网络更快的收敛" class="headerlink" title="优化器optimizer：分批次训练，为了使网络更快的收敛"></a>优化器optimizer：分批次训练，为了使网络更快的收敛</h2><h3 id="1-SGD优化器"><a href="#1-SGD优化器" class="headerlink" title="1.SGD优化器"></a>1.SGD优化器</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911704229-9de6047d-06b0-4613-8c9b-758e3590a03e.png"></p><h3 id="2-SGD-Moementum优化器"><a href="#2-SGD-Moementum优化器" class="headerlink" title="2.SGD+Moementum优化器"></a>2.SGD+Moementum优化器</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911795030-bc996492-74f0-4529-b503-5e8787c81cb1.png"></p><h3 id="3-Adagrad优化器（自适应学习率）"><a href="#3-Adagrad优化器（自适应学习率）" class="headerlink" title="3.Adagrad优化器（自适应学习率）"></a>3.Adagrad优化器（自适应学习率）</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911909581-6511d462-5f87-40c6-ab92-3732fb650c0f.png"></p><h3 id="4-RMSProp优化器（自适应学习率）"><a href="#4-RMSProp优化器（自适应学习率）" class="headerlink" title="4.RMSProp优化器（自适应学习率）"></a>4.RMSProp优化器（自适应学习率）</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738911967584-b0fcf198-69a6-4f40-8a8d-c67432b77f25.png"></p><h3 id="5-Adam优化器（自适应学习率）"><a href="#5-Adam优化器（自适应学习率）" class="headerlink" title="5.Adam优化器（自适应学习率）"></a>5.Adam优化器（自适应学习率）</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738912033673-8dc8f94d-b795-4469-94fa-4f2be0ac69df.png"></p><h3 id="6-总览"><a href="#6-总览" class="headerlink" title="6.总览"></a>6.总览</h3><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738912100915-36e4e81d-72c9-49c1-b017-736083ad1b5a.png"></p><h1 id="video3-pytorch-demo"><a href="#video3-pytorch-demo" class="headerlink" title="video3:pytorch demo"></a>video3:pytorch demo</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1738912519122-0b6ca640-97e3-449e-ac34-684da13be146.png"></p><h2 id="test1-official-demo"><a href="#test1-official-demo" class="headerlink" title="test1_official_demo"></a>test1_official_demo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)<span class="comment">#卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)<span class="comment">#卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行图像格式转换</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50000张训练图片的数据集下载</span></span><br><span class="line"><span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                         download=<span class="literal">False</span>, transform=transform)</span><br><span class="line"><span class="comment">#创建训练数据加载器，设置批量大小、是否打乱数据和工作线程数</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">36</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 10000张验证图片</span></span><br><span class="line">val_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">False</span>, transform=transform)</span><br><span class="line"><span class="comment">#创建验证数据加载器，设置批量大小、是否打乱数据和工作线程数</span></span><br><span class="line">val_loader = torch.utils.data.DataLoader(val_set, batch_size=<span class="number">10000</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 创建一个迭代器 val_data_iter，用于遍历 val_loader。</span></span><br><span class="line"><span class="comment"># 使用 next 函数从迭代器中获取一批验证数据，包括图像 val_image 和标签 val_label</span></span><br><span class="line">val_data_iter = <span class="built_in">iter</span>(val_loader)</span><br><span class="line">val_image, val_label = <span class="built_in">next</span>(val_data_iter)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"><span class="comment"># 初始化LeNet模型</span></span><br><span class="line">net = LeNet()</span><br><span class="line"><span class="comment"># 定义损失函数为交叉熵损失</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 使用Adam优化器，学习率为0.001</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = loss_function(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:    <span class="comment"># print every 500 mini-batches</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                outputs = net(val_image)  <span class="comment"># [batch, 10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = torch.eq(predict_y, val_label).<span class="built_in">sum</span>().item() / val_label.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;/n [%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line"><span class="comment">#使用 torch.save 函数保存神经网络 net 的状态字典（即模型参数）到指定路径。</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/__mermaid_v3/7cbe5a2ec49a252efc8df44dd63282c7.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 使用 transform 函数对图像进行转换，输出格式为 [通道数, 高度, 宽度]。</span></span><br><span class="line">im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line"><span class="comment"># 使用 torch.unsqueeze 增加一个维度，使图像张量的形状变为 [批次大小, 通道数, 高度, 宽度]。</span></span><br><span class="line">im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># [N, C, H, W]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.no_grad() 禁用梯度计算，提高推理速度</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    <span class="comment"># 对输出进行处理，取最大值对应的类别索引，并转换为 numpy 数组。</span></span><br><span class="line">    predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测结果：&#x27;</span>+classes[<span class="built_in">int</span>(predict)])</span><br></pre></td></tr></table></figure><h1 id="video4-tensorflow-demo"><a href="#video4-tensorflow-demo" class="headerlink" title="video4:tensorflow demo"></a>video4:tensorflow demo</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1739001055794-fdf74acb-c28e-461e-906c-bedc939f53f0.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1739001466021-1db3c6f9-8906-403e-a0ce-f3e50924e5d2.png" alt="卷积过程不需要padding参数的时候设置为valid （filter卷积核）"></p><h2 id="test1-official-demo-1"><a href="#test1-official-demo-1" class="headerlink" title="test1_official_demo"></a>test1_official_demo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten, Conv2D</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 卷积层，第一个参数为卷积核的个数，第二个参数为卷积核的大小，第三个参数为激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        <span class="comment"># 展平操作</span></span><br><span class="line">        <span class="variable language_">self</span>.flatten = Flatten()</span><br><span class="line">        <span class="comment"># 全连接层，第一个参数为输出的维度，第二个参数为激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.d2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">        <span class="comment">#softmax返回的概率分布值，即预测值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正向传播过程</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)      <span class="comment"># input[batch, 28, 28, 1] output[batch, 26, 26, 32]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)    <span class="comment"># output [batch, 21632]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.d1(x)         <span class="comment"># output [batch, 128]</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.d2(x)      <span class="comment"># output [batch, 10]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, division, print_function, unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> MyModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手写数字的一个数据集</span></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># download and load data</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># imgs = x_test[:3]</span></span><br><span class="line"><span class="comment"># labs = y_test[:3]</span></span><br><span class="line"><span class="comment"># print(labs)</span></span><br><span class="line"><span class="comment"># #对图片进行水平方向上的拼接</span></span><br><span class="line"><span class="comment"># plot_imags = np.hstack(imgs)</span></span><br><span class="line"><span class="comment"># plt.imshow(plot_imags, cmap=&#x27;gray&#x27;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a channels dimension</span></span><br><span class="line">x_train = x_train[..., tf.newaxis]</span><br><span class="line">x_test = x_test[..., tf.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># create data generator</span></span><br><span class="line"><span class="comment"># 使用 tf.data.Dataset.from_tensor_slices 将训练和测试数据转换为 TensorFlow 数据集。</span></span><br><span class="line"><span class="comment"># 对训练数据进行打乱（shuffle）操作，缓冲区大小为10000。</span></span><br><span class="line"><span class="comment"># 将训练和测试数据集按批次（batch）处理，每批次包含32个样本。</span></span><br><span class="line">train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line">test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define loss</span></span><br><span class="line"><span class="comment"># 创建一个稀疏分类交叉熵损失函数对象。该损失函数用于计算真实标签与预测概率之间的差异，适用于多分类问题，其中真实标签为整数形式的类别索引。</span></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define optimizer</span></span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train_loss and train_accuracy</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">&#x27;train_loss&#x27;</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;train_accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train_loss and train_accuracy</span></span><br><span class="line">test_loss = tf.keras.metrics.Mean(name=<span class="string">&#x27;test_loss&#x27;</span>)</span><br><span class="line">test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;test_accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train function including calculating loss, applying gradient and calculating accuracy</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">images, labels</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 用于跟踪梯度</span></span><br><span class="line">        <span class="comment"># 正向传播</span></span><br><span class="line">        predictions = model(images)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = loss_object(labels, predictions)</span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    <span class="comment"># 应用梯度来进行优化</span></span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, model.trainable_variables))</span><br><span class="line">    <span class="comment"># 更新训练损失和准确率</span></span><br><span class="line">    train_loss(loss)</span><br><span class="line">    train_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define test function including calculating loss and calculating accuracy</span></span><br><span class="line"><span class="comment"># 装饰器作用：将python代码转为tensorflow的计算图（图模型结构，理解为静态图），不能在再进行调试但可以提高运行效率</span></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">images, labels</span>):</span><br><span class="line">    <span class="comment"># 测试过程中不需要更新梯度，不用with tf.GradientTape()</span></span><br><span class="line">    <span class="comment"># 正向传播</span></span><br><span class="line">    predictions = model(images)</span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    t_loss = loss_object(labels, predictions)</span><br><span class="line">    <span class="comment"># 更新测试损失和准确率</span></span><br><span class="line">    test_loss(t_loss)</span><br><span class="line">    test_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    train_loss.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line">    train_accuracy.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line">    test_loss.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line">    test_accuracy.reset_state()  <span class="comment"># clear history info</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(images, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> test_images, test_labels <span class="keyword">in</span> test_ds:</span><br><span class="line">        test_step(test_images, test_labels)</span><br><span class="line"></span><br><span class="line">    template = <span class="string">&#x27;Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;%, Test Loss: &#123;&#125;, Test Accuracy: &#123;&#125;%&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(template.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                          train_loss.result(),</span><br><span class="line">                          train_accuracy.result() * <span class="number">100</span>,</span><br><span class="line">                          test_loss.result(),</span><br><span class="line">                          test_accuracy.result() * <span class="number">100</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="video5：AlexNet"><a href="#video5：AlexNet" class="headerlink" title="video5：AlexNet"></a>video5：AlexNet</h1><p><img src="https://cdn.nlark.com/yuque/0/2025/png/32561980/1739867109895-6a18ad3f-b848-42cc-8c55-2a3f218340ea.png"></p><h1 id="video6-AlexNet与花分类（pytorch）"><a href="#video6-AlexNet与花分类（pytorch）" class="headerlink" title="video6:AlexNet与花分类（pytorch）"></a>video6:AlexNet与花分类（pytorch）</h1><h1 id="video7-AlexNet与花分类（TensorFlow）"><a href="#video7-AlexNet与花分类（TensorFlow）" class="headerlink" title="video7:AlexNet与花分类（TensorFlow）"></a>video7:AlexNet与花分类（TensorFlow）</h1>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重新开始</title>
      <link href="/2025/02/19/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B/"/>
      <url>/2025/02/19/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B/</url>
      
        <content type="html"><![CDATA[<p>花费一天的时间终于把我的小博客给搞回来啦，接下来就是开始记录啦😍</p><h1 id="把我的小站重新搞回来啦！😘"><a href="#把我的小站重新搞回来啦！😘" class="headerlink" title="把我的小站重新搞回来啦！😘"></a>把我的小站重新搞回来啦！😘</h1><hr>]]></content>
      
      
      <categories>
          
          <category> 个人杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>归档分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>about</title>
      <link href="/about/index1.html"/>
      <url>/about/index1.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>about Easy</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<h1 id="halo-这里是关于Easy的2025计划"><a href="#halo-这里是关于Easy的2025计划" class="headerlink" title="halo!,这里是关于Easy的2025计划"></a>halo!,这里是关于Easy的2025计划</h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><blockquote><p>2025关键词</p></blockquote><ul><li>突破</li><li>锻炼</li><li>学习</li><li>Friends</li></ul><h2 id="个人目标"><a href="#个人目标" class="headerlink" title="个人目标"></a>个人目标</h2><blockquote><p>九宫格计划表</p></blockquote><table><thead><tr><th><strong>🎓</strong>**  学习成长**</th><th></th><th><strong>🎢</strong>**  体验突破**</th><th></th><th><strong>⛺️</strong>**  休闲娱乐**</th></tr></thead><tbody><tr><td>- [ ] 学一门新的语言<br/>- [ ] 完成蓝桥杯比赛（先报名再说😅）<br/>- [ ] 考个什么证试试</td><td></td><td>- [ ] 体验 1 次蹦极和高空跳伞<br/>- [ ] 体验 1 次即兴戏剧<br/>- [ ] 认识 几个个新朋友</td><td></td><td>- [ ] 周末出门玩</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>📃</strong>**  工作事业**</td><td></td><td><strong>💡</strong>** 关键词**</td><td></td><td><strong>👪</strong>**  家庭生活**</td></tr><tr><td>- [ ] 还没上班呢<br/>- [ ] 规划事业方向<br/>- [ ] 研究就业</td><td></td><td><strong>突破</strong><br/><strong>健康</strong><br/><strong>锻炼</strong></td><td></td><td>- [ ] 多回家玩<br/></td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>🧘‍♀️</strong>**  身心健康**</td><td></td><td><strong>💰</strong>** 收支理财**</td><td></td><td><strong>👭</strong>** 人际社交**</td></tr><tr><td>- [ ] 早睡早起<br/>- [ ] 养成无氧锻炼的习惯<br/>- [ ] 减脂</td><td></td><td>- [ ] 减少不必要的开支<br/>- [ ] 尝试投资</td><td></td><td>- [ ] 相亲相爱一家人<br/>- [ ] 维护朋友关系</td></tr></tbody></table><h2 id="任务清单"><a href="#任务清单" class="headerlink" title="任务清单"></a>任务清单</h2><blockquote><p>Todo List 。</p></blockquote><ul><li><font style="background:#F6E1AC;color:#664900">每周</font> 保持四天以上的锻炼</li><li><font style="background:#DBF1B7;color:#2A4200">每天</font> 每天保持 8 小时睡眠，早睡呐😅</li><li><font style="background:#EFF0F0;color:#262626">双周</font> 每两周进行一次规划</li><li><font style="background:#C0DDFC;color:#00346B">每月</font> 每月回顾一次当月情况</li></ul><h2 id="好习惯和坏习惯"><a href="#好习惯和坏习惯" class="headerlink" title="好习惯和坏习惯"></a>好习惯和坏习惯</h2><blockquote><p>为完成目标，设置 3-5 条坚持做和禁止做的事情。</p></blockquote><p><strong>我要做的</strong></p><ol><li>早睡早起、每日睡眠 ≥ 8h</li><li>保持锻炼习惯</li><li>每周都要学点东西</li></ol><p>…</p><p><strong>我不要做的</strong></p><ol><li>躺着玩手机</li><li>吃垃圾食品</li><li>生气</li><li>乱花钱</li></ol><p>…</p>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>留言板</title>
      <link href="/comments/index.html"/>
      <url>/comments/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>链接</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/kslink.css"/>
      <url>/css/kslink.css</url>
      
        <content type="html"><![CDATA[/* 添加友链按钮 *//* 快速填写格式 */.addBtn {    display: flex;    justify-content: center;    flex-wrap: wrap;}.addBtn button {    transition: .2s;    display: flex;    margin: 5px auto;    color: var(--global-bg);    padding: 15px;    border-radius: 40px;    background: var(--search-result-title);    align-items: center;}button {    padding: 0;    outline: 0;    border: none;    background: 0 0;    cursor: pointer;    touch-action: manipulation;}.fa-solid, .fas {    font-family: "Font Awesome 6 Free";    font-weight: 900;}.addBtn i {    font-size: 1.3rem;    margin-right: 10px;}.addBtn button:hover {    background: var(--theme-color);    color: #fff;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/kslink.js"/>
      <url>/js/kslink.js</url>
      
        <content type="html"><![CDATA[var leonus = {    linkCom: e => {        var t = document.querySelector(".el-textarea__inner");        "bf" == e ? (t.value = "```yml\n", t.value += "- name: \n  link: \n  avatar: \n  descr: \n  siteshot: ", t.value += "\n```", t.setSelectionRange(15, 15)) : (t.value = "站点名称：\n站点地址：\n头像链接：\n站点描述：\n站点截图：", t.setSelectionRange(5, 5)), t.focus()    },    owoBig: () => {        if (!document.getElementById("post-comment") || document.body.clientWidth < 768) return;        let e = 1,            t = "",            o = document.createElement("div"),            n = document.querySelector("body");        o.id = "owo-big", n.appendChild(o), new MutationObserver((l => {            for (let a = 0; a < l.length; a++) {                let i = l[a].addedNodes,                    s = "";                if (2 == i.length && "OwO-body" == i[1].className) s = i[1];                else {                    if (1 != i.length || "tk-comment" != i[0].className) continue;                    s = i[0]                }                s.onmouseover = l => {                    e && ("OwO-body" == s.className && "IMG" == l.target.tagName || "tk-owo-emotion" == l.target.className) && (e = 0, t = setTimeout((() => {                        let e = 3 * l.path[0].clientHeight,                            t = 3 * l.path[0].clientWidth,                            a = l.x - l.offsetX - (t - l.path[0].clientWidth) / 2,                            i = l.y - l.offsetY;                        a + t > n.clientWidth && (a -= a + t - n.clientWidth + 10), a < 0 && (a = 10), o.style.cssText = `display:flex; height:${e}px; width:${t}px; left:${a}px; top:${i}px;`, o.innerHTML = `<img src="${l.target.src}">`                    }), 300))                }, s.onmouseout = () => {                    o.style.display = "none", e = 1, clearTimeout(t)                }            }        })).observe(document.getElementById("post-comment"), {            subtree: !0,            childList: !0        })    },};]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
